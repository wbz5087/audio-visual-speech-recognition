{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "(rate,sig) = wav.read(\"audio/data/ABOUT/train/ABOUT_00005.wav\")\n",
    "mfcc_feat = mfcc(sig,rate,numcep=26,nfilt = 26,winlen=0.025,winstep=0.0085)\n",
    "#mfcc_feat = np.reshape(mfcc_feat,[mfcc_feat.shape[1],mfcc_feat.shape[0]])\n",
    "print(mfcc_feat.shape)\n",
    "plt.plot(mfcc_feat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "c = mfcc_feat.flatten('F')\n",
    "c.resize(29*math.ceil(mfcc_feat.shape[0]*mfcc_feat.shape[1]/29))\n",
    "re = c.reshape(29,int(c.shape[0]/29))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import librosa\n",
    "y, sr = librosa.load('audio/data/ABUSE/train/ABUSE_00006.wav',sr = None)\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "#mfccs = np.reshape(mfccs,[mfccs.shape[1],mfccs.shape[0]])\n",
    "plt.plot(mfccs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_audio_list(path,p):\n",
    "    print(\"[INFO] loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    train_y = []\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    \n",
    "    labels = os.listdir(path)\n",
    "    #labels.remove('.DS_Store')\n",
    "    imagePaths = []\n",
    "    print(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        path_file=os.path.join(path, label)\n",
    "        #path_file = os.path.join(path,'label')\n",
    "        path_files = os.path.join(path_file,p)\n",
    "        imagePath = os.listdir(path_files)\n",
    "        #print(path_files)\n",
    "        #imagePath.remove('.DS_Store')\n",
    "        for img in imagePath:\n",
    "            if img == '.DS_Store':\n",
    "                print('wrong')\n",
    "            else:\n",
    "                image = os.path.join(path_files,img)\n",
    "                imagePaths.append(image)\n",
    "            #print(path_files)\n",
    "    #print(imagePaths)\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "    \n",
    "    return imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import helpers\n",
    "from helpers import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n",
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]]\n",
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n"
     ]
    }
   ],
   "source": [
    "audio = Audio(path='audio/data/')\n",
    "trainlist=audio.generate_audio_list(p='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "valX,valY = audio.load_audio(p='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "part='test'\n",
    "testX,testY = audio.load_audio(p=part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Y=valY.toarray()\n",
    "test_Y = testY.toarray()\n",
    "#train_Y = trainY.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainX = np.reshape(trainX,(-1,26,121))\n",
    "valX = np.reshape(valX,(-1,26,121))\n",
    "testX = np.reshape(testX,(-1,26,121))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D,Conv3D,Conv1D\n",
    "from keras.layers.convolutional import MaxPooling2D,MaxPooling3D,MaxPooling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM,Input,GlobalAveragePooling1D\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "import tensorflow as tf\n",
    "#from keras.layers.extra import TimeDistributedConvolution2D, TimeDistributedMaxPooling2D, TimeDistributedFlatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_audio = Input(shape = (26,121))\n",
    "\n",
    "conv1d_1 = Conv1D(64,kernel_size = 3,strides=1, padding = 'same',\n",
    "               activation = 'relu')(input_audio)\n",
    "\n",
    "batch_norm1 = BatchNormalization()(conv1d_1)\n",
    "\n",
    "batch_norm1 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm1)\n",
    "\n",
    "conv1d_2 = Conv1D(128,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm1)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm2)\n",
    "\n",
    "conv1d_2 = Conv1D(128,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm2)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm2)\n",
    "\n",
    "bilstm1 = Bidirectional(LSTM(256,return_sequences=True))(batch_norm2)\n",
    "bilstm2 = Bidirectional(LSTM(256,return_sequences=True),name = 'bilstm2')(bilstm1)\n",
    "\n",
    "avgpool = GlobalAveragePooling1D()(bilstm2)\n",
    "\n",
    "dense1 = Dense(256,activation='relu')(avgpool)\n",
    "batch_norm3 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(class_num,activation = 'softmax')(batch_norm3)\n",
    "#maxpooling1d = MaxPooling1D(pool_size=2, padding='same')(batch_norm2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 26, 121)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 26, 64)            23296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 26, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 13, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 13, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 7, 128)            49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 4, 512)            788480    \n",
      "_________________________________________________________________\n",
      "bilstm2 (Bidirectional)      (None, 4, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 771       \n",
      "=================================================================\n",
      "Total params: 2,595,075\n",
      "Trainable params: 2,593,923\n",
      "Non-trainable params: 1,152\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_audio], \n",
    "              outputs=[dense2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_audio.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "46/46 [==============================] - 14s 315ms/step - loss: 0.0133 - acc: 0.9997 - val_loss: 0.0440 - val_acc: 0.9800\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 12s 257ms/step - loss: 0.0103 - acc: 1.0000 - val_loss: 0.0413 - val_acc: 0.9800\n",
      "Epoch 3/5\n",
      "31/46 [===================>..........] - ETA: 3s - loss: 0.0081 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "sample_number = len(trainlist)\n",
    "model.fit_generator(audio.generate_arrays_from_file(filelist=trainlist),\n",
    "                        validation_data=(valX, val_Y),\n",
    "                        steps_per_epoch=sample_number // 64,\n",
    "                        epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(trainX, train_Y, epochs=5, batch_size=64, \n",
    "          verbose=1, validation_data=(valX, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmodel=load_model('try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmodel.summary()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "trymodel = Model(inputs=[input_audio], \n",
    "              outputs=[dense2])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#trymodel.trainable = False\n",
    "trymodel.load_weights('try.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate_layer_model = Model(inputs=xmodel.input,\n",
    "#                                  outputs=xmodel.get_layer('bilstm2').output)\n",
    "# newmodel.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "# \tmetrics=[\"accuracy\"])\n",
    "intermediate = xmodel.get_layer('bilstm2').output\n",
    "avgpool1 = GlobalAveragePooling1D()(intermediate)\n",
    "\n",
    "dense11 = Dense(256,activation='relu')(avgpool1)\n",
    "batch_norm11 = BatchNormalization()(dense11)\n",
    "dense11 = Dense(64,activation='relu')(batch_norm11)\n",
    "batch_norm12 = BatchNormalization()(dense11)\n",
    "dense12 = Dense(class_num,activation = 'softmax')(batch_norm12)\n",
    "#m = intermediate_layer_model.predict(testX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 26, 121)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 26, 64)            23296     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 26, 64)            256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 13, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 13, 128)           24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 13, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 7, 128)            49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 4, 512)            788480    \n",
      "_________________________________________________________________\n",
      "bilstm2 (Bidirectional)      (None, 4, 512)            1574912   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_4 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                16448     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 2,611,203\n",
      "Trainable params: 2,609,923\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = Model(inputs=[xmodel.input], \n",
    "              outputs=[dense12])\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9)\n",
    "model1.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "46/46 [==============================] - 15s 322ms/step - loss: 0.2686 - acc: 0.8940 - val_loss: 0.0744 - val_acc: 0.9733\n",
      "Epoch 2/5\n",
      "46/46 [==============================] - 12s 252ms/step - loss: 0.0274 - acc: 0.9966 - val_loss: 0.0596 - val_acc: 0.9800\n",
      "Epoch 3/5\n",
      "46/46 [==============================] - 12s 269ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 0.0560 - val_acc: 0.9800\n",
      "Epoch 4/5\n",
      "46/46 [==============================] - 12s 255ms/step - loss: 0.0117 - acc: 1.0000 - val_loss: 0.0535 - val_acc: 0.9800\n",
      "Epoch 5/5\n",
      "46/46 [==============================] - 13s 275ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 0.0517 - val_acc: 0.9800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ac4b240>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_number = len(trainlist)\n",
    "model1.fit_generator(audio.generate_arrays_from_file(filelist=trainlist),\n",
    "                        validation_data=(valX, val_Y),\n",
    "                        steps_per_epoch=sample_number // 64,\n",
    "                        epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model1.fit(trainX, train_Y, epochs=5, batch_size=64, \n",
    "          verbose=1, validation_data=(valX, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150/150 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12325750867525737, 0.9666666666666667]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX,test_Y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input_audio = Input(shape = (19456,1))\n",
    "conv1d_1 = Conv1D(64,kernel_size = 80,strides=4, padding = 'same',\n",
    "               activation = 'relu')(input_audio)\n",
    "\n",
    "batch_norm1 = BatchNormalization()(conv1d_1)\n",
    "\n",
    "batch_norm1 = MaxPooling1D(pool_size=4,padding = 'same')(batch_norm1)\n",
    "\n",
    "conv1d_2 = Conv1D(64,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm1)\n",
    "conv1d_2 = Conv1D(64,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(conv1d_2)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm2)\n",
    "\n",
    "conv1d_2 = Conv1D(128,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm2)\n",
    "conv1d_2 = Conv1D(128,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(conv1d_2)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=4,padding = 'same')(batch_norm2)\n",
    "\n",
    "conv1d_2 = Conv1D(256,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm2)\n",
    "conv1d_2 = Conv1D(256,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(conv1d_2)\n",
    "conv1d_2 = Conv1D(256,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(conv1d_2)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=4,padding = 'same')(batch_norm2)\n",
    "\n",
    "conv1d_2 = Conv1D(512,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(batch_norm2)\n",
    "conv1d_2 = Conv1D(512,kernel_size = 3, strides = 1, padding = 'same',\n",
    "               activation = 'relu')(conv1d_2)\n",
    "\n",
    "batch_norm2 = BatchNormalization()(conv1d_2)\n",
    "batch_norm2 = MaxPooling1D(pool_size=2,padding = 'same')(batch_norm2)\n",
    "\n",
    "#tf.split\n",
    "\n",
    "bilstm1 = Bidirectional(LSTM(256,return_sequences=True))(batch_norm2)\n",
    "bilstm2 = Bidirectional(LSTM(256,return_sequences=True),name = 'bilstm2')(bilstm1)\n",
    "\n",
    "avgpool = GlobalAveragePooling1D()(bilstm2)\n",
    "\n",
    "#dense1 = Dense(256,activation='relu')(avgpool)\n",
    "#batch_norm3 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(class_num,activation = 'softmax')(avgpool)\n",
    "#maxpooling1d = MaxPooling1D(pool_size=2, padding='same')(batch_norm2)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
