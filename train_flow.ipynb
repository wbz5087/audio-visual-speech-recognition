{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "labels = os.listdir('save/')\n",
    "imagePaths = []\n",
    "print(labels)\n",
    "for i, label in enumerate(labels):\n",
    "    if label != '.DS_Store':\n",
    "        path_file=os.path.join(\"save\", label)\n",
    "        #path_file = os.path.join(path,'label')\n",
    "        path_files = os.path.join(path_file,'train')\n",
    "        imagePath = sorted(list(paths.list_images(path_files)))\n",
    "        imagePaths.append(imagePath)\n",
    "        print(path_files)\n",
    "        #print(imagePath)\n",
    "print(imagePaths)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "flattened_image = []\n",
    "\n",
    "#flatten the lis\n",
    "for x in imagePaths:\n",
    "    for y in x:\n",
    "        flattened_image.append(y)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "path='save/ABOUT/train/ABOUT_00001'\n",
    "imagePaths = sorted(list(paths.list_images(path)))\n",
    "data=[]\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    #image = cv2.resize(image, (norm_size, norm_size))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "data1 = np.reshape(data,(120,120,29))\n",
    "len(data),data.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "aaa='AAAA_0001'\n",
    "ss=aaa.split('_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_list(path,p):\n",
    "    print(\"[INFO] loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    train_y = []\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    \n",
    "    labels = os.listdir(path)\n",
    "    #labels.remove('.DS_Store')\n",
    "    imagePaths = []\n",
    "    print(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        path_file=os.path.join(path, label)\n",
    "        #path_file = os.path.join(path,'label')\n",
    "        path_files = os.path.join(path_file,p)\n",
    "        imagePath = os.listdir(path_files)\n",
    "        #print(path_files)\n",
    "        #imagePath.remove('.DS_Store')\n",
    "        for img in imagePath:\n",
    "            if img == '.DS_Store':\n",
    "                print('wrong')\n",
    "            else:\n",
    "                image = os.path.join(path_files,img)\n",
    "                imagePaths.append(image)\n",
    "            #print(path_files)\n",
    "    #print(imagePaths)\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "    \n",
    "    return imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['ACTION', 'ALLEGATIONS', 'AFFAIRS', 'ABUSE', 'ALLOWED', 'ALLOW']\n"
     ]
    }
   ],
   "source": [
    "part='train'\n",
    "trainlist = generate_file_list(path='backup/',p=part) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open('filelist.txt', 'w')\n",
    "for ip in trainlist:\n",
    "    fileObject.write(ip)\n",
    "    fileObject.write('\\n')\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "fd = open( \"filelist.txt\", \"r\" )\n",
    "\n",
    "for line in fd.readlines():\n",
    "    train_list.append(line.rstrip('\\n'))\n",
    "    #print(line)\n",
    "#print(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_GRAY(path,p):\n",
    "    print(\"[INFO] loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    train_y = []\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    \n",
    "    labels = os.listdir(path)\n",
    "    #labels.remove('.DS_Store')\n",
    "    imagePaths = []\n",
    "    print(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        path_file=os.path.join(path, label)\n",
    "        #path_file = os.path.join(path,'label')\n",
    "        path_files = os.path.join(path_file,p)\n",
    "        imagePath = os.listdir(path_files)\n",
    "        #print(path_files)\n",
    "        #imagePath.remove('.DS_Store')\n",
    "        for img in imagePath:\n",
    "            if img == '.DS_Store':\n",
    "                print('wrong')\n",
    "            else:\n",
    "                image = os.path.join(path_files,img)\n",
    "                imagePaths.append(image)\n",
    "            #print(path_files)\n",
    "    #print(imagePaths)\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "    #print(imagePaths)\n",
    "    # loop over the input images\n",
    "    for imagePath in imagePaths:\n",
    "        image_path = sorted(list(paths.list_images(imagePath)))\n",
    "        images=[]\n",
    "        for img in image_path:\n",
    "            \n",
    "            # load the image, pre-process it, and store it in the data list\n",
    "            image = cv2.imread(img)\n",
    "            #image = cv2.resize(image, (norm_size, norm_size))\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            #image = cv2.resize(image, (norm_size, norm_size))\n",
    "            image = img_to_array(image)\n",
    "            #print(image)\n",
    "            #image = np.array(image, dtype=\"float\") / 255.0\n",
    "            #print(image.shape)\n",
    "            image = np.reshape(image,(120,120))\n",
    "            images.append(image)\n",
    "        \n",
    "        images=np.array(images,dtype=\"float\")\n",
    "        if(len(images)==0):\n",
    "            print(imagePath)\n",
    "            break\n",
    "        #images=np.reshape(images,(120,120,29))\n",
    "        #print(images.shape)\n",
    "        #print(images.shape)\n",
    "        data.append(images)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "        #label = int(imagePath.split(os.path.sep)[-2])\n",
    "        basename = os.path.basename(imagePath)\n",
    "        label = basename.split('_')\n",
    "        train_y.append(label[0])\n",
    "        #print(len(labels))\n",
    "    #data = np.array(data, dtype=\"float\") / 255.0\n",
    "    data = np.array(data, dtype=\"float\")\n",
    "    #print(data.shape)\n",
    "\n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    train_y = np.array(train_y)\n",
    "    print(train_y.shape)\n",
    "    # 整数编码\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_result = label_encoder.fit_transform(train_y)\n",
    "    # One-Hot编码\n",
    "    one_hot_encoder = OneHotEncoder()\n",
    "# One-Hot编码将分类值映射到整数值再表示成二进制向量\n",
    "    integer_result1 = integer_result.reshape(len(integer_result), 1)\n",
    "    one_hot_result = one_hot_encoder.fit_transform(integer_result1)\n",
    "\n",
    "    #labels = np.array(labels)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    #labels = to_categorical(labels, num_classes=CLASS_NUM)                         \n",
    "    return data,one_hot_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['ACTION', 'ALLEGATIONS', 'AFFAIRS', 'ABUSE', 'ALLOWED', 'ALLOW']\n",
      "(300,)\n",
      "[INFO] loading images...\n",
      "['ACTION', 'ALLEGATIONS', 'AFFAIRS', 'ABUSE', 'ALLOWED', 'ALLOW']\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "part='val'\n",
    "valX,valY = load_data_GRAY(path='backup/',p=part) \n",
    "\n",
    "part='test'\n",
    "testX,testY = load_data_GRAY(path='backup/',p=part) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_Y=valY.toarray()\n",
    "test_Y = testY.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras import backend as K\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "#from keras.layers.extra import TimeDistributedConvolution2D, TimeDistributedMaxPooling2D, TimeDistributedFlatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallerVGGNet:\n",
    "\t@staticmethod\n",
    "\tdef build(width, height, depth, classes):\n",
    "\t\t# initialize the model along with the input shape to be\n",
    "\t\t# \"channels last\" and the channels dimension itself\n",
    "\t\tmodel = Sequential()\n",
    "\t\tinputShape = (height, width, depth)\n",
    "\t\tchanDim = -1\n",
    "\n",
    "\t\t# if we are using \"channels first\", update the input shape\n",
    "\t\t# and channels dimension\n",
    "\t\tif K.image_data_format() == \"channels_first\":\n",
    "\t\t\tinputShape = (depth, height, width)\n",
    "\t\t\tchanDim = 1\n",
    "        \t\t# CONV => RELU => POOL\n",
    "\t\tmodel.add(Conv2D(96, (3, 3), padding=\"same\",\n",
    "\t\t\tinput_shape=inputShape))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\t\t#model.add(Dropout(0.25))\n",
    "        \t\t# (CONV => RELU) * 2 => POOL\n",
    "\t\tmodel.add(Conv2D(256, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\t\tmodel.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\t#model.add(Dropout(0.25))\n",
    "        \t\t# (CONV => RELU) * 2 => POOL\n",
    "\t\tmodel.add(Conv2D(512, (3, 3), padding=\"same\"))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "\t\t#model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "\t\t#model.add(Activation(\"relu\"))\n",
    "\t\t#model.add(BatchNormalization(axis=chanDim))\n",
    "\t\t#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\t\t#model.add(Dropout(0.25))\n",
    "        \t\t# first (and only) set of FC => RELU layers\n",
    "# \t\tmodel.add(TimeDistributed(Flatten())\n",
    "# \t\tmodel.add(LSTM(512, return_sequences=True))\n",
    "# \t\tmodel.add(BatchNormalization())\n",
    "# \t\tmodel.add(LSTM(12, return_sequences=True))\n",
    "# \t\tmodel.add(BatchNormalization())\n",
    "\t\tmodel.add(Flatten())\n",
    "\t\tmodel.add(Dense(4096))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\t#model.add(Dropout(0.5))\n",
    "\t\tmodel.add(Dense(4096))\n",
    "\t\tmodel.add(Activation(\"relu\"))\n",
    "\t\tmodel.add(BatchNormalization())\n",
    "\t\t# softmax classifier\n",
    "\t\tmodel.add(Dense(classes))\n",
    "\t\tmodel.add(Activation(\"softmax\"))\n",
    "        \n",
    "\t\t# return the constructed network architecture\n",
    "\t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "INIT_LR = 0.1\n",
    "BS = 16\n",
    "IMAGE_DIMS = (120,120,29)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "\tdepth=IMAGE_DIMS[2], classes=6)\n",
    "#opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "valX = np.reshape(valX,(-1,120,120,29))\n",
    "testX = np.reshape(testX,(-1,120,120,29))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(trainX, train_Y, epochs=10, batch_size=16, verbose=1, validation_data=(testX, test_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = os.listdir(\"backup/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_result = label_encoder.fit(Y)\n",
    "integer_result = label_encoder.transform(Y)\n",
    "# One-Hot编码\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "# One-Hot编码将分类值映射到整数值再表示成二进制向量\n",
    "integer_result1 = integer_result.reshape(len(integer_result), 1)\n",
    "#integer_result1 = integer_result1.flatten()\n",
    "Y = one_hot_encoder.fit(integer_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = one_hot_encoder.transform(integer_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arrays_from_file(path,batch_size):  \n",
    "    while 1:  \n",
    "        f = path\n",
    "        cnt = 0  \n",
    "        X =[]  \n",
    "        Y =[]  \n",
    "        for line in f:  \n",
    "            #print(line)\n",
    "            # create Numpy arrays of input data  \n",
    "            # and labels, from each line in the file  \n",
    "            image_path = sorted(list(paths.list_images(line)))\n",
    "            images=[]\n",
    "            for img in image_path:\n",
    "\n",
    "                # load the image, pre-process it, and store it in the data list\n",
    "                image = cv2.imread(img)\n",
    "                #image = cv2.resize(image, (norm_size, norm_size))\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "                #image = cv2.resize(image, (norm_size, norm_size))\n",
    "                image = img_to_array(image)\n",
    "                #print(image)\n",
    "                #image = np.array(image, dtype=\"float\") / 255.0\n",
    "                #print(image.shape)\n",
    "                image = np.reshape(image,(120,120))\n",
    "                images.append(image)\n",
    " \n",
    "            images = np.array(images,dtype=\"float\")\n",
    "            if(len(images)==0):\n",
    "                print(imagePath)\n",
    "                break\n",
    "            #images=np.reshape(images,(120,120,29))\n",
    "            #print(images.shape)\n",
    "            #print(images.shape)\n",
    "            X.append(images)\n",
    "\n",
    "            # extract the class label from the image path and update the\n",
    "            # labels list\n",
    "            #label = int(imagePath.split(os.path.sep)[-2])\n",
    "            basename = os.path.basename(line)\n",
    "            label = basename.split('_')\n",
    "            Y.append(label[0]) \n",
    "            \n",
    "            #X = np.array(X, dtype=\"float\")\n",
    "            #print(data.shape)\n",
    "\n",
    "            # scale the raw pixel intensities to the range [0, 1]\n",
    "\n",
    "            \n",
    "            cnt += 1  \n",
    "            if cnt==batch_size:  \n",
    "                cnt = 0 \n",
    "                #print(Y)\n",
    "                #Y = np.array(Y)\n",
    "                #print(Y.shape)\n",
    "                # 整数编码\n",
    "                integer_result = label_encoder.transform(Y)\n",
    "                #print(integer_result)\n",
    "                integer_result1 = integer_result.reshape(len(integer_result), 1)\n",
    "                Y = one_hot_encoder.transform(integer_result1)\n",
    "                Y = Y.toarray()\n",
    "                #print(Y.shape)\n",
    "                \n",
    "                X = np.array(X, dtype=\"float\")\n",
    "                X = np.reshape(X,(-1,120,120,29))\n",
    "                #print(X.shape)\n",
    "                yield (X, Y)  \n",
    "                X = []  \n",
    "                Y = []  \n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend.tensorflow_backend as KTF\n",
    "\n",
    "# 指定第一块GPU可用 \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "config = tf.ConfigProto()  \n",
    "config.gpu_options.allow_growth=True   #不全部占满显存, 按需分配\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "KTF.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "Epoch 1/5\n",
      "12/92 [==>...........................] - ETA: 150s - loss: 0.1103 - acc: 0.9753"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-fb892965906a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_Y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5900\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \tepochs=5, verbose=1)\n\u001b[0m",
      "\u001b[0;32m/home/oscar/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oscar/anaconda2/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1095\u001b[0m                                         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1097\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oscar/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/oscar/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1843\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1844\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1845\u001b[0;31m                             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1846\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"[INFO] training network...\")\n",
    "H = model.fit_generator(\n",
    "\tgenerate_arrays_from_file(train_list,batch_size=64),\n",
    "\tvalidation_data=(valX, val_Y),\n",
    "\tsteps_per_epoch=5900 // 64,\n",
    "\tepochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 3s     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9814994224905967, 0.6866666666666666]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(testX,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
