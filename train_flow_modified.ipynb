{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from imutils import paths\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam,SGD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = os.listdir(\"save/\")\n",
    "Y.remove('.DS_Store')\n",
    "label_encoder = LabelEncoder()\n",
    "integer_result = label_encoder.fit(Y)\n",
    "integer_result = label_encoder.transform(Y)\n",
    "# One-Hot编码\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "# One-Hot编码将分类值映射到整数值再表示成二进制向量\n",
    "integer_result1 = integer_result.reshape(len(integer_result), 1)\n",
    "#integer_result1 = integer_result1.flatten()\n",
    "Y = one_hot_encoder.fit(integer_result1)\n",
    "\n",
    "Y = one_hot_encoder.transform(integer_result1)\n",
    "\n",
    "Y.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_list(path,p):\n",
    "    print(\"[INFO] loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    train_y = []\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    \n",
    "    labels = os.listdir(path)\n",
    "    #labels.remove('.DS_Store')\n",
    "    labels.remove('.DS_Store')\n",
    "    imagePaths = []\n",
    "    print(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        path_file=os.path.join(path, label)\n",
    "        #path_file = os.path.join(path,'label')\n",
    "        path_files = os.path.join(path_file,p)\n",
    "        imagePath = os.listdir(path_files)\n",
    "        #print(path_files)\n",
    "        #imagePath.remove('.DS_Store')\n",
    "        for img in imagePath:\n",
    "            if img == '.DS_Store':\n",
    "                print('wrong')\n",
    "            else:\n",
    "                image = os.path.join(path_files,img)\n",
    "                imagePaths.append(image)\n",
    "            #print(path_files)\n",
    "    #print(imagePaths)\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "    \n",
    "    return imagePaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n",
      "wrong\n",
      "wrong\n"
     ]
    }
   ],
   "source": [
    "part='train'\n",
    "trainlist = generate_file_list(path='save/',p=part) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open('filelist.txt', 'w')\n",
    "for ip in trainlist:\n",
    "    fileObject.write(ip)\n",
    "    fileObject.write('\\n')\n",
    "fileObject.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = []\n",
    "fd = open( \"filelist.txt\", \"r\" )\n",
    "\n",
    "for line in fd.readlines():\n",
    "    train_list.append(line.rstrip('\\n'))\n",
    "    #print(line)\n",
    "#print(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path,p):\n",
    "    print(\"[INFO] loading images...\")\n",
    "    data = []\n",
    "    labels = []\n",
    "    train_y = []\n",
    "    # grab the image paths and randomly shuffle them\n",
    "    \n",
    "    labels = os.listdir(path)\n",
    "    labels.remove('.DS_Store')\n",
    "    imagePaths = []\n",
    "    print(labels)\n",
    "    for i, label in enumerate(labels):\n",
    "        path_file=os.path.join(path, label)\n",
    "        #path_file = os.path.join(path,'label')\n",
    "        path_files = os.path.join(path_file,p)\n",
    "        imagePath = os.listdir(path_files)\n",
    "        #print(path_files)\n",
    "        #imagePath.remove('.DS_Store')\n",
    "        for img in imagePath:\n",
    "            if img == '.DS_Store':\n",
    "                print('wrong')\n",
    "            else:\n",
    "                image = os.path.join(path_files,img)\n",
    "                imagePaths.append(image)\n",
    "            #print(path_files)\n",
    "    #print(imagePaths)\n",
    "    random.seed(42)\n",
    "    random.shuffle(imagePaths)\n",
    "    #print(imagePaths)\n",
    "    # loop over the input images\n",
    "    for imagePath in imagePaths:\n",
    "        image_path = sorted(list(paths.list_images(imagePath)))\n",
    "        images=[]\n",
    "        for img in image_path:\n",
    "            \n",
    "            # load the image, pre-process it, and store it in the data list\n",
    "            image = cv2.imread(img)\n",
    "            #image = cv2.resize(image, (norm_size, norm_size))\n",
    "            #image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            #image = cv2.resize(image, (norm_size, norm_size))\n",
    "            image = img_to_array(image)\n",
    "            #print(image)\n",
    "            #image = np.array(image, dtype=\"float\") / 255.0\n",
    "            #print(image.shape)\n",
    "            image = np.reshape(image,(120,120,3))\n",
    "            images.append(image)\n",
    "        \n",
    "        images=np.array(images,dtype=\"float\")\n",
    "        if(len(images)==0):\n",
    "            print(imagePath)\n",
    "            break\n",
    "        #images=np.reshape(images,(120,120,29))\n",
    "        #print(images.shape)\n",
    "        #print(images.shape)\n",
    "        data.append(images)\n",
    "\n",
    "        # extract the class label from the image path and update the\n",
    "        # labels list\n",
    "        #label = int(imagePath.split(os.path.sep)[-2])\n",
    "        basename = os.path.basename(imagePath)\n",
    "        label = basename.split('_')\n",
    "        train_y.append(label[0])\n",
    "        #print(len(labels))\n",
    "    #data = np.array(data, dtype=\"float\") / 255.0\n",
    "    data = np.array(data, dtype=\"float\")\n",
    "    #print(data.shape)\n",
    "\n",
    "    # scale the raw pixel intensities to the range [0, 1]\n",
    "    train_y = np.array(train_y)\n",
    "    print(train_y.shape)\n",
    "    # 整数编码\n",
    "    integer_result = label_encoder.transform(train_y)\n",
    "    # One-Hot编码\n",
    "    #one_hot_encoder = OneHotEncoder()\n",
    "# One-Hot编码将分类值映射到整数值再表示成二进制向量\n",
    "    integer_result1 = integer_result.reshape(len(integer_result), 1)\n",
    "    y_label = one_hot_encoder.transform(integer_result1)\n",
    "\n",
    "    #labels = np.array(labels)\n",
    "\n",
    "    # convert the labels from integers to vectors\n",
    "    #labels = to_categorical(labels, num_classes=CLASS_NUM)                         \n",
    "    return data,y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n",
      "(150,)\n",
      "[INFO] loading images...\n",
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n",
      "wrong\n",
      "wrong\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "part='val'\n",
    "valX,valY = load_data(path='save/',p=part) \n",
    "\n",
    "part='test'\n",
    "testX,testY = load_data(path='save/',p=part) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "['ABSOLUTELY', 'ABOUT', 'ABUSE']\n",
      "wrong\n",
      "wrong\n",
      "(2959,)\n"
     ]
    }
   ],
   "source": [
    "part='train'\n",
    "trainX,trainY = load_data(path='save/',p=part)\n",
    "train_Y=trainY.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val_Y=valY.toarray()\n",
    "test_Y = testY.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D,Conv3D\n",
    "from keras.layers.convolutional import MaxPooling2D,MaxPooling3D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import LSTM,Input\n",
    "from keras import backend as K\n",
    "from keras.layers.wrappers import TimeDistributed, Bidirectional\n",
    "#from keras.layers.extra import TimeDistributedConvolution2D, TimeDistributedMaxPooling2D, TimeDistributedFlatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputShape = (29,120,120,3)\n",
    "input1 = Input(shape = (29,120,120,3))\n",
    "\n",
    "conv3d = Conv3D(64,(5,7,7),padding = 'same',\n",
    "                strides = (1,2,2), activation='relu')(input1)\n",
    "batch_norm1 = BatchNormalization()(conv3d)\n",
    "maxpool3d = MaxPooling3D(pool_size=(1,2,2),padding='same')(batch_norm1)\n",
    "\n",
    "time_conv2d = TimeDistributed(Conv2D(128,(3,3),activation = 'relu'))(maxpool3d)\n",
    "batch_norm2 = BatchNormalization()(time_conv2d)\n",
    "time_maxpool2d = TimeDistributed(MaxPooling2D(2,2))(batch_norm2)\n",
    "\n",
    "time_conv2d = TimeDistributed(Conv2D(256,(3,3),activation = 'relu'))(time_maxpool2d)\n",
    "batch_norm3 = BatchNormalization()(time_conv2d)\n",
    "time_maxpool2d = TimeDistributed(MaxPooling2D(2,2))(batch_norm3)\n",
    "\n",
    "time_flatten = TimeDistributed(Flatten())(time_maxpool2d)\n",
    "\n",
    "bilstm1 = Bidirectional(LSTM(128,return_sequences=True))(time_flatten)\n",
    "bilstm2 = Bidirectional(LSTM(128,return_sequences=True))(bilstm1)\n",
    "\n",
    "flatten = Flatten()(bilstm2)\n",
    "dense1 = Dense(1024,activation='relu')(flatten)\n",
    "batch_norm4 = BatchNormalization()(dense1)\n",
    "dense2 = Dense(class_num,activation = 'softmax')(batch_norm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 29, 120, 120, 3)   0         \n",
      "_________________________________________________________________\n",
      "conv3d_1 (Conv3D)            (None, 29, 60, 60, 64)    47104     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 29, 60, 60, 64)    256       \n",
      "_________________________________________________________________\n",
      "max_pooling3d_1 (MaxPooling3 (None, 29, 30, 30, 64)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 29, 28, 28, 128)   73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 29, 28, 28, 128)   512       \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 29, 14, 14, 128)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 29, 12, 12, 256)   295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 29, 12, 12, 256)   1024      \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 29, 6, 6, 256)     0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 29, 9216)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 29, 256)           9569280   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 29, 256)           394240    \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 7424)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              7603200   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 3075      \n",
      "=================================================================\n",
      "Total params: 17,991,811\n",
      "Trainable params: 17,988,867\n",
      "Non-trainable params: 2,944\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input1], \n",
    "              outputs=[dense2])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "with open('mlp_model.json','w') as of:\n",
    "    of.write(json_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model_video.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EPOCHS = 3\n",
    "# INIT_LR = 0.1\n",
    "# BS = 16\n",
    "# IMAGE_DIMS = (120,120,29)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range = 10, width_shift_range=0.1,\n",
    "\theight_shift_range=0.1, zoom_range=0.2,\n",
    "\thorizontal_flip=True, fill_mode=\"nearest\")\n",
    "# aug = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "# model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],\n",
    "# \tdepth=IMAGE_DIMS[2], classes=6)\n",
    "#opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,\n",
    "\tmetrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2959 samples, validate on 150 samples\n",
      "Epoch 1/1\n",
      "  32/2959 [..............................] - ETA: 25:00:02 - loss: 1.8230 - acc: 0.2188"
     ]
    }
   ],
   "source": [
    "model.fit(trainX, train_Y, epochs=1, batch_size=32, \n",
    "          verbose=1, validation_data=(valX, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"[INFO] training network...\")\n",
    "# H = model.fit_generator(\n",
    "# \taug.flow(trainX, train_Y, batch_size=32),\n",
    "# \tvalidation_data=(testX, test_Y),\n",
    "# \tsteps_per_epoch=len(trainX) // 32,\n",
    "# \tepochs=EPOCHS, verbose=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "valX = np.reshape(valX,(-1,120,120,29))\n",
    "testX = np.reshape(testX,(-1,120,120,29))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model.fit(valX, val_Y, epochs=10, batch_size=16, \n",
    "          verbose=1, validation_data=(testX, test_Y))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def generate_arrays_from_file(path,batch_size):  \n",
    "    while 1:  \n",
    "        random.shuffle(path)\n",
    "        f = path\n",
    "        cnt = 0  \n",
    "        X =[]  \n",
    "        Y =[]  \n",
    "        for line in f:  \n",
    "            #print(line)\n",
    "            # create Numpy arrays of input data  \n",
    "            # and labels, from each line in the file  \n",
    "            image_path = sorted(list(paths.list_images(line)))\n",
    "            images=[]\n",
    "            seed = random.randint(0,100)\n",
    "            for img in image_path:\n",
    "\n",
    "                # load the image, pre-process it, and store it in the data list\n",
    "                image = cv2.imread(img)\n",
    "                #print(image.shape)\n",
    "                #image = cv2.resize(image, (norm_size, norm_size))\n",
    "                image = aug.random_transform(image,seed = seed)\n",
    "                #image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "                \n",
    "                #image = cv2.resize(image, (norm_size, norm_size))\n",
    "                image = img_to_array(image)\n",
    "                #print(image)\n",
    "                #image = np.array(image, dtype=\"float\") / 255.0\n",
    "                #print(image.shape)\n",
    "                image = np.reshape(image,(120,120,3))\n",
    "                \n",
    "                #print(image.shape)\n",
    "                \n",
    "                images.append(image)\n",
    "                \n",
    "            images = np.array(images,dtype=\"float\")\n",
    "            #print(images.shape)\n",
    "            if(len(images)==0):\n",
    "                print(line)\n",
    "                break\n",
    "            #images=np.reshape(images,(120,120,29))\n",
    "            X.append(images)\n",
    "\n",
    "            # extract the class label from the image path and update the\n",
    "            # labels list\n",
    "            #label = int(imagePath.split(os.path.sep)[-2])\n",
    "            basename = os.path.basename(line)\n",
    "            label = basename.split('_')\n",
    "            Y.append(label[0]) \n",
    "            \n",
    "            #X = np.array(X, dtype=\"float\")\n",
    "            #print(data.shape)\n",
    "\n",
    "            # scale the raw pixel intensities to the range [0, 1]\n",
    "\n",
    "            \n",
    "            cnt += 1  \n",
    "            if cnt==batch_size:  \n",
    "                cnt = 0 \n",
    "                integer_result = label_encoder.transform(Y)\n",
    "                #print(integer_result)\n",
    "                integer_result1 = integer_result.reshape(len(integer_result), 1)\n",
    "                Y = one_hot_encoder.transform(integer_result1)\n",
    "                Y = Y.toarray()\n",
    "                #print(Y.shape)\n",
    "                \n",
    "                X = np.array(X, dtype=\"float\")\n",
    "                print(X.shape)\n",
    "                yield (X, Y)  \n",
    "                X = []  \n",
    "                Y = []  \n",
    "    f.close() "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from keras_tqdm import TQDMNotebookCallback"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "print(\"[INFO] training network...\")\n",
    "sample_number = len(train_list)\n",
    "#print(sample_number)\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True,\n",
    "mode='max')\n",
    "callbacks_list = [checkpoint,TQDMNotebookCallback()]\n",
    "\n",
    "model.fit_generator(generate_arrays_from_file(train_list,batch_size=16),\n",
    "                        validation_data=(valX, val_Y),\n",
    "                        steps_per_epoch=sample_number // 16,\n",
    "                        epochs=5, verbose=2,\n",
    "                   callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(testX,test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
